{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing experimental Jun lab data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, copy, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('code')\n",
    "from functions_response import process_fsglt, process_fsglt20, fit_normal_fsglt, fit_lognormal_fsglt, process_jts, make_daughterID_jts, make_integer_IDs\n",
    "\n",
    "sys.path.append(os.path.join('..','colicycle','colicycle'))\n",
    "import exp_parameters as ep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "direxp = os.path.join('.','experiments')\n",
    "if not os.path.isdir(direxp):\n",
    "    os.makedirs(direxp)\n",
    "\n",
    "dirdata = os.path.join('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Si & Le Treut (2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing experiment MG1655 M9 acetate\n",
      "./experiments/mg1655_acetate/colidata.pkl\n",
      "Importing experiment MG1655 MOPS glucose\n",
      "./experiments/mg1655_glucose/colidata.pkl\n",
      "Importing experiment MG1655 MOPS glycerol 11aa\n",
      "./experiments/mg1655_glycerol11aa/colidata.pkl\n",
      "Importing experiment NCM3722 MOPS arginine\n",
      "./experiments/ncm3722_arginine/colidata.pkl\n",
      "Importing experiment NCM3722 MOPS glucose\n",
      "./experiments/ncm3722_glucose/colidata.pkl\n",
      "Importing experiment NCM3722 MOPS glucose 12aa\n",
      "./experiments/ncm3722_glucose12aa/colidata.pkl\n"
     ]
    }
   ],
   "source": [
    "fname = '2019FSGLT.xlsx'\n",
    "fpath_in = os.path.join(dirdata, fname)\n",
    "\n",
    "exp_map = {\n",
    "    'mg1655_acetate': 'MG1655 M9 acetate', \\\n",
    "    'mg1655_glucose': 'MG1655 MOPS glucose', \\\n",
    "    'mg1655_glycerol11aa': 'MG1655 MOPS glycerol 11aa', \\\n",
    "    'ncm3722_arginine': 'NCM3722 MOPS arginine', \\\n",
    "    'ncm3722_glucose': 'NCM3722 MOPS glucose', \\\n",
    "    'ncm3722_glucose12aa': 'NCM3722 MOPS glucose 12aa' \\\n",
    "}\n",
    "\n",
    "for name in exp_map.keys():\n",
    "    sheet_name = exp_map[name]\n",
    "    print(\"Importing experiment {:s}\".format(sheet_name))\n",
    "    df = pd.read_excel(fpath_in, sheet_name=sheet_name)\n",
    "    \n",
    "    sel = ['elongation rate (1/hour)',\n",
    "           'initiation size per ori (micron)',\n",
    "           'division size (micron)', 'newborn size (micron)',\n",
    "           'added size (micron)', 'cell width (micron)', \n",
    "           'generation time (minute)', 'tau_cyc (minute)', 'septum position',\n",
    "           'cell ID', 'daughter ID']\n",
    "\n",
    "    # reorder columns\n",
    "    df = df[sel]\n",
    "\n",
    "    # rename columns\n",
    "    col_mapping = {\n",
    "        'elongation rate (1/hour)': 'lambda', \\\n",
    "        'initiation size per ori (micron)': 'Lambda_i', \\\n",
    "        'tau_cyc (minute)': 'taucyc', \\\n",
    "        'division size (micron)': 'Sd', \\\n",
    "        'newborn size (micron)': 'Sb', \\\n",
    "        'added size (micron)': 'Delta_bd', \\\n",
    "        'cell width (micron)': 'width', \\\n",
    "        'generation time (minute)': 'tau', \\\n",
    "        'tau_cyc (minute)': 'tau_cyc', \\\n",
    "        'septum position': 'phi'}\n",
    "\n",
    "    df.rename(columns=col_mapping, inplace=True)\n",
    "\n",
    "    # convert growth rate to per minutes\n",
    "    df['lambda'] = df['lambda'] / 60.\n",
    "    df['tau_eff'] = np.log(2.)/df['lambda']\n",
    "\n",
    "    # process the data frame to add attributes\n",
    "    process_fsglt(df)\n",
    "    \n",
    "    # choose a method for the computation of delta_id and delta_ii\n",
    "    # see source code for details\n",
    "    col_mapping = { \\\n",
    "                   'delta_id_m1': 'delta_id', \\\n",
    "                   'delta_ii_forward': 'delta_ii', \\\n",
    "                   }\n",
    "    df.rename(columns=col_mapping, inplace=True)\n",
    "\n",
    "    # save the dataframe\n",
    "    fname = \"{:s}.pkl\".format(name)\n",
    "    outputdir = os.path.join(direxp, name)\n",
    "    if not os.path.isdir(outputdir):\n",
    "        os.makedirs(outputdir)\n",
    "    fpath = os.path.join(outputdir,'colidata.pkl')\n",
    "    df.to_pickle(fpath)\n",
    "    print(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Le Treut & Si & Li (2020) -- MG1655 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing experiment MG1655 MOPS acetate uracil\n",
      "./experiments/mg1655_acetate_uracil/colidata.pkl\n",
      "Importing experiment MG1655 MOPS glycerol 6aa uracil\n",
      "./experiments/mg1655_glycerol6aa_uracil/colidata.pkl\n",
      "Importing experiment MG1655 MOPS glucose uracil\n",
      "./experiments/mg1655_glucose_uracil/colidata.pkl\n"
     ]
    }
   ],
   "source": [
    "fname = '2020GLTFSDL.xlsx'\n",
    "fpath_in = os.path.join(dirdata, fname)\n",
    "\n",
    "exp_map = {\n",
    "#     'bw25113_glucose': 'BW25113 MOPS glucose', \\\n",
    "#     'bw25113_glucose_uracil': 'BW25113 MOPS glucose uracil', \\\n",
    "#     'jh642_mannose': 'B. subtilis S750 mannose', \\\n",
    "    'mg1655_acetate_uracil': 'MG1655 MOPS acetate uracil' , \\\n",
    "    'mg1655_glycerol6aa_uracil': 'MG1655 MOPS glycerol 6aa uracil', \\\n",
    "    'mg1655_glucose_uracil': 'MG1655 MOPS glucose uracil', \\\n",
    "}\n",
    "\n",
    "for name in exp_map.keys():\n",
    "    sheet_name = exp_map[name]\n",
    "    print(\"Importing experiment {:s}\".format(sheet_name))\n",
    "    df = pd.read_excel(fpath_in, sheet_name=sheet_name)\n",
    "    \n",
    "    sel = ['elongation rate (1/hour)',\n",
    "           'initiation size per ori (micron)',\n",
    "           'division size (micron)', 'newborn size (micron)',\n",
    "           'added size (micron)', 'cell width (micron)', \n",
    "           'generation time (minute)', 'tau_cyc (minute)', 'septum position',\n",
    "           'cell ID', 'daughter ID']\n",
    "\n",
    "    # reorder columns\n",
    "    df = df[sel]\n",
    "\n",
    "    # rename columns\n",
    "    col_mapping = {\n",
    "        'elongation rate (1/hour)': 'lambda', \\\n",
    "        'initiation size per ori (micron)': 'Lambda_i', \\\n",
    "        'tau_cyc (minute)': 'taucyc', \\\n",
    "        'division size (micron)': 'Sd', \\\n",
    "        'newborn size (micron)': 'Sb', \\\n",
    "        'added size (micron)': 'Delta_bd', \\\n",
    "        'cell width (micron)': 'width', \\\n",
    "        'generation time (minute)': 'tau', \\\n",
    "        'tau_cyc (minute)': 'tau_cyc', \\\n",
    "        'septum position': 'phi'}\n",
    "\n",
    "    df.rename(columns=col_mapping, inplace=True)\n",
    "\n",
    "    # convert growth rate to per minutes\n",
    "    df['lambda'] = df['lambda'] / 60.\n",
    "    df['tau_eff'] = np.log(2.)/df['lambda']\n",
    "\n",
    "    # process the data frame to add attributes\n",
    "    process_fsglt(df)\n",
    "    \n",
    "    # choose a method for the computation of delta_id and delta_ii\n",
    "    # see source code for details\n",
    "    col_mapping = { \\\n",
    "                   'delta_id_m1': 'delta_id', \\\n",
    "                   'delta_ii_forward': 'delta_ii', \\\n",
    "                   }\n",
    "    df.rename(columns=col_mapping, inplace=True)\n",
    "\n",
    "    # save the dataframe\n",
    "    fname = \"{:s}.pkl\".format(name)\n",
    "    outputdir = os.path.join(direxp, name)\n",
    "    if not os.path.isdir(outputdir):\n",
    "        os.makedirs(outputdir)\n",
    "    fpath = os.path.join(outputdir,'colidata.pkl')\n",
    "    df.to_pickle(fpath)\n",
    "    print(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Le Treut & Si & Li (2020) -- BW and B. subtilis data\n",
    "In this dataformat, there is not cell ID nor daughter ID information. The initiation-to-initiation adder was directly computed in upstream data processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing experiment BW25113 MOPS glucose\n",
      "./experiments/bw25113_glucose/colidata.pkl\n",
      "Importing experiment BW25113 MOPS glucose uracil\n",
      "./experiments/bw25113_glucose_uracil/colidata.pkl\n",
      "Importing experiment B. subtilis S750 mannose\n",
      "./experiments/jh642_mannose/colidata.pkl\n"
     ]
    }
   ],
   "source": [
    "fname = '2020GLTFSDL.xlsx'\n",
    "fpath_in = os.path.join(dirdata, fname)\n",
    "\n",
    "exp_map = {\n",
    "    'bw25113_glucose': 'BW25113 MOPS glucose', \\\n",
    "    'bw25113_glucose_uracil': 'BW25113 MOPS glucose uracil', \\\n",
    "    'jh642_mannose': 'B. subtilis S750 mannose'\n",
    "}\n",
    "\n",
    "for name in exp_map.keys():\n",
    "    sheet_name = exp_map[name]\n",
    "    print(\"Importing experiment {:s}\".format(sheet_name))\n",
    "    df = pd.read_excel(fpath_in, sheet_name=sheet_name)\n",
    "    \n",
    "    sel = ['elongation rate (1/hour)',\n",
    "           'initiation size per ori (micron)',\n",
    "           'division size (micron)', 'newborn size (micron)',\n",
    "           'added size (micron)', 'cell width (micron)', \n",
    "           'generation time (minute)', 'tau_cyc (minute)', 'septum position',\n",
    "           'added initiation size per ori (micron)']\n",
    "\n",
    "    # reorder columns\n",
    "    df = df[sel]\n",
    "\n",
    "    # rename columns\n",
    "    col_mapping = {\n",
    "        'elongation rate (1/hour)': 'lambda', \\\n",
    "        'initiation size per ori (micron)': 'Lambda_i', \\\n",
    "        'tau_cyc (minute)': 'taucyc', \\\n",
    "        'division size (micron)': 'Sd', \\\n",
    "        'newborn size (micron)': 'Sb', \\\n",
    "        'added size (micron)': 'Delta_bd', \\\n",
    "        'added initiation size per ori (micron)': 'delta_ii_forward', \\\n",
    "        'cell width (micron)': 'width', \\\n",
    "        'generation time (minute)': 'tau', \\\n",
    "        'tau_cyc (minute)': 'tau_cyc', \\\n",
    "        'septum position': 'phi'}\n",
    "\n",
    "    df.rename(columns=col_mapping, inplace=True)\n",
    "\n",
    "    # convert growth rate to per minutes\n",
    "    df['lambda'] = df['lambda'] / 60.\n",
    "    df['tau_eff'] = np.log(2.)/df['lambda']\n",
    "\n",
    "    # process the data frame to add attributes\n",
    "    process_fsglt20(df)\n",
    "\n",
    "    # choose a method for the computation of delta_id and delta_ii\n",
    "    # see source code for details\n",
    "    col_mapping = { \\\n",
    "                   'delta_id_m1': 'delta_id', \\\n",
    "                   'delta_ii_forward': 'delta_ii', \\\n",
    "                   }\n",
    "    df.rename(columns=col_mapping, inplace=True)\n",
    "\n",
    "    # save the dataframe\n",
    "    fname = \"{:s}.pkl\".format(name)\n",
    "    outputdir = os.path.join(direxp, name)\n",
    "    if not os.path.isdir(outputdir):\n",
    "        os.makedirs(outputdir)\n",
    "    fpath = os.path.join(outputdir,'colidata.pkl')\n",
    "    df.to_pickle(fpath)\n",
    "    print(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Sauls et al (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing experiment gly+ 0 uM cam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping cell f16p0685t0472r01 with daughters f16p0685t0491r02 and f16p0685t0491r03\n",
      "skipping cell f31p0255t0423r01 with daughters f31p0255t0453r02 and f31p0255t0453r03\n",
      "./experiments/3610_gly/colidata.pkl\n",
      "Importing experiment man 0 uM cam\n",
      "skipping cell f03p0256t0247r01 with daughters f03p0256t0275r02 and f03p0256t0275r03\n",
      "skipping cell f07p0298t0406r01 with daughters f07p0298t0446r02 and f07p0298t0446r03\n",
      "skipping cell f30p0430t0262r01 with daughters f30p0430t0288r02 and f30p0430t0288r03\n",
      "skipping cell f33p0518t0146r01 with daughters f33p0518t0173r02 and f33p0518t0173r03\n",
      "./experiments/3610_man/colidata.pkl\n",
      "Importing experiment suc 0 uM cam\n",
      "skipping cell f20p0516t0437r01 with daughters f20p0516t0473r02 and f20p0516t0473r03\n",
      "./experiments/3610_suc/colidata.pkl\n"
     ]
    }
   ],
   "source": [
    "fname = '2020JTS.xlsx'\n",
    "fpath_in = os.path.join(dirdata, fname)\n",
    "\n",
    "exp_map = {\n",
    "    '3610_gly': 'gly+ 0 uM cam', \\\n",
    "    '3610_man': 'man 0 uM cam', \\\n",
    "    '3610_suc': 'suc 0 uM cam', \\\n",
    "}\n",
    "\n",
    "\n",
    "for name in exp_map.keys():\n",
    "    sheet_name = exp_map[name]\n",
    "    print(\"Importing experiment {:s}\".format(sheet_name))\n",
    "    df = pd.read_excel(fpath_in, sheet_name=sheet_name)\n",
    "    \n",
    "    # re-name column in agreement with Si & Le Treut (2019) column names\n",
    "    df.reset_index(inplace=True)\n",
    "    col_mapping = {\n",
    "    'id': 'cell ID', \\\n",
    "    'birth length (micron)': 'newborn size (micron)', \\\n",
    "    'division length (micron)': 'division size (micron)', \\\n",
    "    'width (micron)': 'cell width (micron)', \\\n",
    "    'added division length (micron)': 'added size (micron)', \\\n",
    "    'growth rate (1/hour)': 'elongation rate (1/hour)', \\\n",
    "    'C+D (minute)': 'tau_cyc (minute)', \\\n",
    "    'initiation length per ori (micron)': 'initiation size per ori (micron)'\n",
    "    }\n",
    "\n",
    "    df.rename(columns=col_mapping, inplace=True)\n",
    "\n",
    "    # replace None string by None value\n",
    "    for key in df.columns:\n",
    "        idx = df[key].eq('None')\n",
    "        df.loc[idx, key] = None\n",
    "    \n",
    "    # create integer index\n",
    "    ncells = len(df)\n",
    "    df['index'] = range(ncells)\n",
    "\n",
    "    # create daugther ID column and keep only mother cells\n",
    "    make_daughterID_jts(df)\n",
    "    make_integer_IDs(df)\n",
    "    \n",
    "\n",
    "    # fall back on previous formatting\n",
    "    sel = ['elongation rate (1/hour)',\n",
    "           'initiation size per ori (micron)',\n",
    "           'division size (micron)', 'newborn size (micron)',\n",
    "           'added size (micron)', 'cell width (micron)', \n",
    "           'generation time (minute)', 'tau_cyc (minute)', 'septum position',\n",
    "           'cell ID', 'daughter ID']\n",
    "\n",
    "    # reorder columns\n",
    "    df = df[sel]\n",
    "\n",
    "    # rename columns\n",
    "    col_mapping = {\n",
    "        'elongation rate (1/hour)': 'lambda', \\\n",
    "        'initiation size per ori (micron)': 'Lambda_i', \\\n",
    "        'tau_cyc (minute)': 'taucyc', \\\n",
    "        'division size (micron)': 'Sd', \\\n",
    "        'newborn size (micron)': 'Sb', \\\n",
    "        'added size (micron)': 'Delta_bd', \\\n",
    "        'cell width (micron)': 'width', \\\n",
    "        'generation time (minute)': 'tau', \\\n",
    "        'tau_cyc (minute)': 'tau_cyc', \\\n",
    "        'septum position': 'phi'}\n",
    "\n",
    "    df.rename(columns=col_mapping, inplace=True)\n",
    "\n",
    "    # convert growth rate to per minutes\n",
    "    df['lambda'] = df['lambda'] / 60.\n",
    "    df['tau_eff'] = np.log(2.)/df['lambda']\n",
    "\n",
    "    # process the data frame to add attributes\n",
    "    process_jts(df)  # add-hoc processing\n",
    "    \n",
    "    # choose a method for the computation of delta_id and delta_ii\n",
    "    # see source code for details\n",
    "    col_mapping = { \\\n",
    "                   'delta_id_m1': 'delta_id', \\\n",
    "                   'delta_ii_forward': 'delta_ii', \\\n",
    "                   }\n",
    "    df.rename(columns=col_mapping, inplace=True)\n",
    "\n",
    "    # save the dataframe\n",
    "    fname = \"{:s}.pkl\".format(name)\n",
    "    outputdir = os.path.join(direxp, name)\n",
    "    if not os.path.isdir(outputdir):\n",
    "        os.makedirs(outputdir)\n",
    "    fpath = os.path.join(outputdir,'colidata.pkl')\n",
    "    df.to_pickle(fpath)\n",
    "    print(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save parameters for simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mapping = {\n",
    "    'tau_eff': 'tau_fit', \\\n",
    "    'Sb': 'Lb_fit', \\\n",
    "    'Sd': 'Ld_fit', \\\n",
    "    'Lambda_i': 'Li_fit', \\\n",
    "    'delta_ii': 'DLi', \\\n",
    "    'delta_id': 'DLdLi', \\\n",
    "    'Delta_bd': 'dL', \\\n",
    "    'phi': 'phi', \\\n",
    "    'mother ID': 'mother_id',\\\n",
    "    'cell ID': 'cell_id'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mg1655_acetate\n",
      "Loaded mg1655_glucose\n",
      "Loaded mg1655_glycerol11aa\n",
      "Loaded ncm3722_arginine\n",
      "Loaded ncm3722_glucose\n",
      "Loaded ncm3722_glucose12aa\n",
      "Loaded mg1655_acetate_uracil\n",
      "Loaded mg1655_glycerol6aa_uracil\n",
      "Loaded mg1655_glucose_uracil\n",
      "Loaded 3610_gly\n",
      "Loaded 3610_man\n",
      "Loaded 3610_suc\n"
     ]
    }
   ],
   "source": [
    "# the dataset without lineage information will produce an error for the calculation\n",
    "# of the mother/daughter correlation for the growth rate.\n",
    "names = [\n",
    "    'mg1655_acetate', \\\n",
    "    'mg1655_glucose', \\\n",
    "    'mg1655_glycerol11aa', \\\n",
    "    'ncm3722_arginine', \\\n",
    "    'ncm3722_glucose', \\\n",
    "    'ncm3722_glucose12aa', \\\n",
    "#     'bw25113_glucose', \\\n",
    "#     'bw25113_glucose_uracil', \\\n",
    "    'mg1655_acetate_uracil' , \\\n",
    "    'mg1655_glycerol6aa_uracil', \\\n",
    "    'mg1655_glucose_uracil', \\\n",
    "#     'jh642_mannose', \\\n",
    "    '3610_gly', \\\n",
    "    '3610_man', \\\n",
    "    '3610_suc', \\\n",
    "]\n",
    "\n",
    "for name in names:\n",
    "    inputdir = os.path.join(direxp, name)\n",
    "    fname = \"{:s}.pkl\".format('colidata')\n",
    "    fpath = os.path.join(inputdir,fname)\n",
    "    colidata = pd.read_pickle(fpath)\n",
    "    print(\"Loaded {:s}\".format(name))\n",
    "    \n",
    "    # rename and select useful columns\n",
    "    sel = list(col_mapping.values())\n",
    "    colidata = colidata.rename(columns=col_mapping)\n",
    "    colidata = colidata[sel]\n",
    "    colidata=colidata.set_index('cell_id')\n",
    "    colidata\n",
    "    \n",
    "    # compute parameters\n",
    "    \n",
    "    tau_corr = ep.calculate_tau_correlation(colidata,'tau_fit')\n",
    "    bin_pos_tau, valbins_tau, res_fit_tau = fit_lognormal_fsglt(colidata['tau_fit'].dropna(),np.arange(2,6,0.1))\n",
    "    bin_pos_DLi, valbins_DLi, res_fit_DLi = fit_normal_fsglt(colidata['DLi'].dropna(),np.arange(0,2,0.1))\n",
    "    bin_pos_DLdLi, valbins_DLdLi, res_fit_DLdLi = fit_lognormal_fsglt(colidata['DLdLi'].dropna(),np.arange(-1,3,0.1))\n",
    "    bin_pos_Lb, valbins_Lb, res_fit_Lb = fit_normal_fsglt(colidata['Lb_fit'].dropna(),np.arange(0,7,0.1))\n",
    "    bin_pos_Lblog, valbins_Lblog, res_fit_Lblog = fit_lognormal_fsglt(colidata['Lb_fit'].dropna(),np.arange(-1,3,0.1))\n",
    "    bin_pos_dL, valbins_dL, res_fit_dL = fit_normal_fsglt(colidata['dL'].dropna(),np.arange(0,7,0.1))\n",
    "\n",
    "    # same method won't work because only mother cells are retained here\n",
    "    # no 2 cells with same mother.\n",
    "    # divR_std = ep.calculate_div_ratio(colidata)\n",
    "    phi = colidata['phi'].to_numpy()\n",
    "    divR = phi / (1.-phi)\n",
    "    divR = np.concatenate([divR, 1/divR])\n",
    "    divR_std = np.nanstd(divR)\n",
    "\n",
    "    # store the parameters\n",
    "    param_storage={}\n",
    "    param_storage['tau_corr'] = tau_corr\n",
    "    param_storage['fit_logtau'] = res_fit_tau.x\n",
    "    param_storage['fit_DLi'] = res_fit_DLi.x\n",
    "    param_storage['fit_logDLdLi'] = res_fit_DLdLi.x\n",
    "    param_storage['fit_Lb'] = res_fit_Lb.x\n",
    "    param_storage['fit_logLb'] = res_fit_Lblog.x\n",
    "    param_storage['fit_dL'] = res_fit_dL.x\n",
    "    param_storage['divR_std'] = divR_std\n",
    "    \n",
    "    outputdir = os.path.join(direxp, name)\n",
    "    fpath = os.path.join(outputdir,'simul_params.pkl')\n",
    "    with open(fpath, 'wb') as f:\n",
    "        pickle.dump(param_storage, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    # plots\n",
    "    fig,axes = plt.subplots(2,3, figsize=(15,5))\n",
    "    axes[0,0].plot(bin_pos_tau, valbins_tau,'o')\n",
    "    axes[0,0].plot(bin_pos_tau, ep.fun_single_gauss(bin_pos_tau, *res_fit_tau.x))\n",
    "    axes[0,0].set_title('tau_fit')\n",
    "    axes[0,1].plot(bin_pos_DLi, valbins_DLi,'o')\n",
    "    axes[0,1].plot(bin_pos_DLi, ep.fun_single_gauss(bin_pos_DLi, *res_fit_DLi.x))\n",
    "    axes[0,1].set_title('DLi')\n",
    "    axes[0,2].plot(bin_pos_DLdLi, valbins_DLdLi,'o')\n",
    "    axes[0,2].plot(bin_pos_DLdLi, ep.fun_single_gauss(bin_pos_DLdLi, *res_fit_DLdLi.x))\n",
    "    axes[0,2].set_title('DLdLi')\n",
    "    axes[1,0].plot(bin_pos_Lb, valbins_Lb,'o')\n",
    "    axes[1,0].plot(bin_pos_Lb, ep.fun_single_gauss(bin_pos_Lb, *res_fit_Lb.x))\n",
    "    axes[1,0].set_title('Lb')\n",
    "    axes[1,1].plot(bin_pos_Lblog, valbins_Lblog,'o')\n",
    "    axes[1,1].plot(bin_pos_Lblog, ep.fun_single_gauss(bin_pos_Lblog, *res_fit_Lblog.x))\n",
    "    axes[1,1].set_title('Lb_log')\n",
    "    axes[1,2].plot(bin_pos_dL, valbins_dL,'o')\n",
    "    axes[1,2].plot(bin_pos_dL, ep.fun_single_gauss(bin_pos_dL, *res_fit_dL.x))\n",
    "    axes[1,2].set_title('dL')\n",
    "    \n",
    "    outputdir = os.path.join(direxp, name)\n",
    "    fpath = os.path.join(outputdir,'fit_figure')\n",
    "    fig.savefig(fpath + '.png', dpi=300, bbox_inches='tight', pad_inches=0 )\n",
    "    plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
